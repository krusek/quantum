\documentclass{article}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[all]{xy}
\usepackage{ifthen}
\usepackage{makeidx}
\usepackage{physics}
\usepackage{exercise}
\newcommand{\makeind}{\makeindex } \newcommand{\ind}[1]{ } \newcommand{\printind} {}
%\usepackage{hyperref} \hypersetup{backref,colorlinks=true} \renewcommand{\ind}[1]{\index{#1}} \renewcommand{\makeind}{\makeindex} \renewcommand{\printind}{\printindex }
\makeind
\author{Korben Rusek}
\title{Quantum Computing}
\date{6-1-2018}
\pagestyle{myheadings}
\markright{Korben Rusek - Quantum Computing}
\oddsidemargin 0.1in
\evensidemargin 0.0in
\textwidth 6.0in
\begin{document}
\maketitle
\newcommand{\gindex}[2]{|#1\!:\!#2|}
\newcommand{\lcm}{\textrm{lcm}}
\newcommand{\irr}{\textrm{irr}}
\newcommand{\sylp}{$Syl_{p}$}
\newcommand{\phnt}[1]{$\phantom{1}^{#1}$}
\newcommand{\gen}[1]{\langle#1\rangle}
\newcommand{\BN}{\mathbb{N}}
\newcommand{\BZ}{\mathbb{Z}}
\newcommand{\BQ}{\mathbb{Q}}
\newcommand{\BR}{\mathbb{R}}
\newcommand{\BC}{\mathbb{C}}
\newcommand{\BF}{\mathbb{F}}
\newcommand{\CF}{\mathcal{F}}
\newcommand{\CQ}{\mathcal{Q}}
\newcommand{\fa}{\mathfrak{a}}
\newcommand{\fb}{\mathfrak{b}}
\newcommand{\fp}{\mathfrak{p}}
\newcommand{\fq}{\mathfrak{q}}
\newcommand{\fm}{\mathfrak{m}}
\newcommand{\FN}{\mathfrak{N}}
\newcommand{\FR}{\mathfrak{R}}
\newcommand{\set}[1]{\{#1\}}
\newcommand{\trv}{\set{1}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\End}{\mathrm{End}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\chr}{\mathrm{char}}

\theoremstyle{definition}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{definition}[theorem]{Definition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{exercise}{Exercise}[section]

\setcounter{section}{1}
\section{Linear Algebra}
\begin{lemma}
  Let $A$ be a non-singular linear operator.
  If all the eigenvalues of $A$ are $\pm 1$ then $A^2=I$
  \begin{proof}
    Since $A$ is non-singular and normal with eigenvalues $\pm1$ then we
    can write $A=\sum\lambda_i\ket{i}\bra{i}$ with $\ket{i}$ spanning the
    vector space. Then we
    have
    \begin{align*}
      A^2&=\left(\sum_i\lambda_i\ket{i}\bra{i}\right)\left(\sum_j\lambda_j\ket{j}\bra{j}\right) \\
      &=\sum_i\sum_j\lambda_i\ket{i}\bra{i}\lambda_j\ket{j}\bra{j} \\
      &=\sum_i\sum_j\lambda_i\lambda_j\ket{i}\bra{i}\ket{j}\bra{j} \\
      &=\sum_i\sum_j\lambda_i\lambda_j\ket{i}\delta_{i,j}\bra{j} \\
      &=\sum_i\sum_j\lambda_i\lambda_j\delta_{i,j}\ket{i}\bra{j} \\
      &=\sum_i\lambda_i^2\ket{i}\bra{i} \\
      &=\sum_i\ket{i}\bra{i} \\
      &=I
    \end{align*}
  \end{proof}
\end{lemma}

\begin{lemma}
  Let $A=\sum_x\ket{x}\bra{x}-\sum_y\ket{y}\bra{y}$, where $\{\ket{x},\ket{y}\}_{x,y}$ form an orthonormal basis.
  Then
  \[
    f(\theta A) = \frac{f(\theta)+f(-\theta)}{2}I + \frac{f(\theta)-f(-\theta)}{2}A.
  \]
  \begin{proof}
    We can write $A=\sum_x\ket{x}\bra{x}-\sum_y\ket{y}\bra{y}$.
    Let $X=\sum_x \ket{x}\bra{x}$ and
    $Y=\sum_y \ket{y}\bra{y}$. That means that
    $I=X+Y$ and $A=X-Y$. Then we have
    \begin{eqnarray*}
      f(\theta)A&=&\sum_xf(\theta)\ket{x}\bra{x}+\sum_yf(-\theta)\ket{y}\bra{y} \\
      &=&f(\theta)\sum_x\ket{x}\bra{x}+f(-\theta)\sum_y\ket{y}\bra{y} \\
      &=&f(\theta)X+f(-\theta)Y \\
      &=&\frac{f(\theta)}{2}X+\frac{f(\theta)}{2}Y+\frac{f(\theta)}{2}X-\frac{f(\theta)}{2}Y+\frac{f(-\theta)}{2}Y+\frac{f(-\theta)}{2}Y+\frac{f(-\theta)}{2}X-\frac{f(-\theta)}{2}X \\
      &=&\frac{f(\theta)}{2}(X+Y)+\frac{f(-\theta)}{2}(X+Y)+\frac{f(\theta)}{2}(X-Y)-\frac{f(-\theta)}{2}(X-Y) \\
      &=&\frac{f(\theta)+f(-\theta)}{2}I+\frac{f(\theta)-f(-\theta)}{2}A
    \end{eqnarray*}
  \end{proof}
\end{lemma}
\setcounter{exercise}{43}

% 2.44
\begin{exercise}
  Suppose that $A$ is invertible and that $\{A,B\}=[A,B]=0$. Show that $B$ is 0.
  \begin{proof}
    $[A,B]=0$ tells us that $AB=BA$ and $\{A,B\}=0$ tells us that $AB=-BA$. Therefore we
    know that $BA=-BA$. Now multiplying on the right side by $A^{-1}$, we get $B=-B$. Thus
    $-2B=0$ which implies that $B=0$.
  \end{proof}
\end{exercise}

% 2.45
\begin{exercise}
  Show that $[A,B]^\dagger=[B^\dagger,A^\dagger]$.
  \begin{proof}
    \begin{eqnarray*}
      [A,B]^\dagger&=&\left(AB-BA\right)^\dagger \\
      &=&B^\dagger A^\dagger - A^\dagger B^\dagger \\
      &=&[B^\dagger,A^\dagger ].
    \end{eqnarray*}
  \end{proof}
\end{exercise}

% 2.46
\begin{exercise}
  Show that $[A,B]=-[B,A]$.
  \begin{proof}
    \begin{eqnarray*}
      [A,B]&=&AB-BA \\
      &=&- (BA-AB) \\
      &=&-[B,A]
    \end{eqnarray*}
  \end{proof}
\end{exercise}

% 2.47
\begin{exercise}
  Suppose that $A$ and $B$ are Hermitian. Show that $i[A,B]$ is Hermitian.
  \begin{proof}
    Suppose that $A=A^\dagger$ and $B=B^\dagger$. Then we have
    \begin{eqnarray*}
      \left(i[A,B]\right)^\dagger&=&-i[B^\dagger,A^\dagger] \\
      &=&-i[B,A]=i[A,B].
    \end{eqnarray*}
    Therefore $i[A,B]$ is Hermitian.
  \end{proof}
\end{exercise}

\begin{lemma}
  Let $A$ be a diagonalizable matrix. Write $A=\sum_i\lambda_i\ket{i}$. Then $\sqrt{A^\dagger A}=\sum_i|\lambda_i|\ket{i}\bra{i}$.
  \begin{proof}
    The proof is pretty straight forward. We start with
    \begin{eqnarray*}
      A^\dagger A &=& \left(\sum_i \lambda_i^*\ket{i}\bra{i}\right)\left(\sum_i\lambda_i\ket{i}\bra{i}\right) \\
      &=&\sum_i|\lambda_i|^2\ket{i}\bra{i}.
    \end{eqnarray*}
    Therefore $\sqrt{A^\dagger A}=\sum_i|\lambda_i|\ket{i}\bra{i}$.
  \end{proof}
\end{lemma}

% 2.48
\begin{exercise}
What is the polar decomposition of a positive matrix, $P$? Of a unitary matrix, $U$? or a Hermitian matrix, $H$?
\begin{proof}[Positive matrix]
  By the above lemma, for a positive matrix, $P$, $\sqrt{P^\dagger P}=P$. Therefore we have $IP$ or $PI$ as the polar decompositions.
\end{proof}
\begin{proof}[Unitary matrix]
  Suppose $V$ is unitary. By the above lemma $\sqrt{V^\dagger V}=I$. Therefore $V=VI=IV$ is the polar decomposition.
\end{proof}
\begin{proof}[Hermitian matrix]
  Suppose that $H$ is Hermitian. Write $H=\sum_i\lambda_i\ket{i}\bra{i}$. Then $J=\sum_i|\lambda_i|\ket{i}\bra{i}$. Let $a_i$ be defined as $\lambda_i/|\lambda_i|$ when $\lambda_i\ne0$ and $1$ when $\lambda_i=0$. Then $U=\sum_iv_i\ket{i}\bra{i}$.
\end{proof}
\end{exercise}

% 2.49
\begin{exercise}
  Express the polar decomposition of a normal matrix in the outer product representation.
  \begin{proof}
    The solution is similar to what we see in the Hermitian version of the above exercise. $J$ has eigenvalues that are the absolute value of the eigenvalues of $H$. $U$ would have eigenvalues that are the unit vectors of the eigenvalues of $H$ (or 1 when eigenvalues are 0).
  \end{proof}
\end{exercise}

% 2.50
\begin{exercise}
  Find the left and right polar decompositions of the matrix
  \[
  P=\begin{bmatrix}
    1&0 \\
    1&1
  \end{bmatrix}.
  \]
  \begin{proof}
    It is easy to see that the eigenvalues of $P$ is $1$ repeated. Therefore $P$ is positive. Therefore $U=I$ and $J=K=P$.
  \end{proof}
\end{exercise}

\begin{definition}
  We define $H$ to be the Hadamard matrix.
  \[
    H=\frac{1}{\sqrt2}\begin{bmatrix}
    1&1 \\
    1&-1
  \end{bmatrix}.
    \]
\end{definition}

% 2.51
\begin{exercise}
  Verify that th Hadamard gate $H$ is unitary.
  \begin{proof}
    \begin{eqnarray*}
      H^2&=&\frac{1}{2}\begin{bmatrix}
        2&0 \\
        0&2
      \end{bmatrix} = I.
    \end{eqnarray*}
    It is clear that $H^\dagger = H$. Thus $H\dagger H=I$ and $H$ is unitary.
  \end{proof}
\end{exercise}

% 2.52
\begin{exercise}
  Verify that $H^2=I$.
  \begin{proof}
    This was shown in the previous exercise.
  \end{proof}
\end{exercise}

% 2.53
\begin{exercise}
  What are the eigenvalues and eigenvectors of $H$?
  \begin{proof}
    To find the eigenvalues of $H$ we solve the  polynomial equation
    \begin{eqnarray*}
      0&=&(1-\lambda)(-1-\lambda)-1 \\
      &=&(\lambda-1)(\lambda + 1)-1 \\
      &=&\lambda^2-2.
    \end{eqnarray*}
    Thus our eigenvalues are $\lambda=\pm\sqrt2$. To find the eigenvectors we solve the system:
    \begin{eqnarray*}
      x+y&=&\frac{\lambda}{\sqrt2} x \\
      x-y&=&\frac{\lambda}{\sqrt2} y
    \end{eqnarray*}
    Since $(0,1)$ is clearly not an eigenvector we can assume that $x=1$. For $\lambda=1$ we have
    $y=\frac{1-\sqrt2}{\sqrt2}$. For $\lambda=-1$ we get $y=\frac{-1+\sqrt2}{\sqrt2}$. Therefore we have the eigenvectors $(\sqrt2,1-\sqrt2)$ and $(\sqrt2,\sqrt2-1)$ with eigenvalues $1$ and $-1$ respectively.
  \end{proof}
\end{exercise}

% 2.54
\begin{exercise}
  Suppose $A$ and $B$ are commuting Hermitian operators. Prove that $exp(A)exp(B)=exp(A+B)$.
  \begin{proof}
    We can write $A=\sum_ia_i\ket{i}\bra{i}$ and $B=\sum_ib_i\ket{i}\bra{i}$ for some orthonormal basis $\ket{i}$. Then we have
    \[exp(A)=\sum_ie^{a_i}ket{i}\bra{i},\]
    \[exp(B)=\sum_ie^{b_i}ket{i}\bra{i},\]
    and so
    \begin{eqnarray*}
      exp(A)exp(B)&=&\sum_ie^{a_i}e^{b_i}ket{i}\bra{i} \\
       &=&\sum_ie^{a_i+b_i}ket{i}\bra{i} \\
       &=&exp(A+B).
    \end{eqnarray*}
  \end{proof}
\end{exercise}

\begin{definition}
  \[
    U(t_1,t_2)=exp\left[\frac{-iH(t_2-t_1)}{\hbar}\right].
    \]
\end{definition}

% 2.55
\begin{exercise}
  Prove that $U(t_1,t_2)$ is unitary.
  \begin{proof}
    This is simple as $exp(x)$ is non-zero, so $U$ is unitary.
  \end{proof}
\end{exercise}

% 2.56
\begin{exercise}
  Use spectral decomposition to show that $K=-i\log(U)$ is Hermitian for any unitary $U$, and thus $U=\exp(iK)$ for some Hermitian $K$.
  \begin{proof}
    Let $U$ be unitary. Then we can write $U=\sum\alpha_\phi\ket{\phi}\bra{\phi}$ for some orthonormal basis $\bra{\phi}$ and $\alpha_\phi\ne0$. That means that $K=\sum-i\log(\alpha_\phi)\ket{\phi}\bra{\phi}$. Since $U$ is unitary then $\alpha_\phi=e^{i\theta_\phi}$ for some real $\theta_\phi$. Therefore we can simplify $K$ to
    \[
      K=\sum -i(i\theta_phi)\ket{\phi}\bra{\phi}=\sum\theta_\phi\ket{\phi}\bra{\phi}.
    \]
    Now sime $\theta_\phi$ is real then $K$ is Hermitian. Therefore any unitary operator is $\exp(iK)$ for some Hermitian $K$.
  \end{proof}
\end{exercise}

\setcounter{exercise}{57}

% 2.58
\begin{exercise}
  Suppose we prepare a quantum system in an eigenstate $\ket\psi$ of some observable $M$, with corresponding eigenvalue $m$. What is the average observed value of $M$, and the standard deviation?
  \begin{proof}
    The average observed value of $M$ is given by $E(M)=\bra{\psi}M\ket\psi$. Then we have
    \begin{eqnarray*}
      E(M)&=&\bra\psi M\ket\psi \\
      &=&m\bra\psi\ket\psi \\
      &=&m.
    \end{eqnarray*}
    The standard deviation squared is given by
    \[[\Delta(M)]^2=\langle M^2\rangle-\langle M\langle^2.\]
    We already saw that $\langle M\rangle=m$. And so we have
    \begin{eqnarray*}
      \langle M^2\rangle &=& \bra{\psi}{M^2}\ket{\psi} \\
      &=& \bra\psi mM\ket\psi \\
      &=& m^2\braket\psi \\
      &=& m^2.
    \end{eqnarray*}
    Therefore the standard deviation is $0$.
  \end{proof}
\end{exercise}

% 2.59
\begin{exercise}
  Suppose we have a qubit in the state $\ket0$, and we measure the observable $X$. What is the average value of $X$? What is the standard deviation of $X$?
  \begin{proof}
    The average value is given by $\bra{0}X\ket{0}=\bra0\ket{1}=0$.

    The standard deviation squared is
    \[
      \bra{0}X^2\ket{0}=\bra{0}\ket{0}=1.
    \]
  \end{proof}
\end{exercise}

% 2.60
\begin{exercise}
  Show that $v\cdot\sigma$ has eigenvalues $\pm1$ and that the projectors onto the correspnding eigenspaces are given by $P_\pm=(I\pm v\cdot\sigma)/2$.
  \begin{proof}
    We have already seen that $v\cdot\sigma$ has eigenvalues $\pm1$. It is easy to verify that the eigenvectors of $v\cdot\sigma$ are
    \[e_\pm=\begin{bmatrix}
      1\pm c \\
      a\pm bi
    \end{bmatrix}.\]
    Furthermore $P\pm e_\pm = e_\pm.$ Therefore $P_\pm$ are the projectors.
  \end{proof}
\end{exercise}

% 2.61
\begin{exercise}
  Calculate the probability of obtaining $+1$ for a measurement of $v\cdot\sigma$, given that the state prior to measurement is $\ket0$. What is the state of the system after the measurement?
  \begin{proof}
    The value $p(+1)$ is given by $\bra0P_+\ket0$. This gives
  $\frac{1}{2}\bra0\ket{\begin{bmatrix}
    1+c \\
    a+bi
  \end{bmatrix}}=\frac{1+c}{2}.$

  After measurement the state of the system is \[\frac{P_+\ket0}{\sqrt{p(+1)}}=\begin{bmatrix}
    1+c \\
    a+bi
  \end{bmatrix}\sqrt\frac{2}{1+c}\]
  \end{proof}
\end{exercise}

%2.62
\begin{exercise}
  Show that any measurement where the measurement operators and the POVM elements coincide is a projective measurement.
  \begin{proof}
    Let $M_m$ be the collection of measurement operators. We will show that $M_m=M_m^\dagger M_m$. Since $M_m=E_n$ for some $n$, then $M_m^\dagger M_m=E_n^\dagger E_n=E_n=M_m$. This means that $M_m$ is positive. In that case $M_m^\dagger = M_m$ and we have $M_m$ is projective as $M_m^2=M_m$.
  \end{proof}
\end{exercise}

%2.63
\begin{exercise}
  Suppose a measurement is described by measurement operators, $M_m$. Show that there exist unitary operators $U_m$ such that $M_m=U_m\sqrt{E_m}$, where $E_m$ is the POVM associated to the measurement.
  \begin{proof}
    Write $M_m=\sum \lambda_i\ket{i}\bra{i}$. Then $E_m=M_m^\dagger M_m=\sum |\lambda_i|^2\ket{i}\bra{i}$. Therefore $U_m=\sum_i\frac{\lambda_i}{|\lambda_i|}\ket{i}\bra{i}$.
  \end{proof}
\end{exercise}

% 2.64
\begin{exercise}
  Suppose Bob is given a quantum state chosen from a set $\ket{\psi_1},\dots,\ket{\psi_m}$ of linearly independent states. Construct a POVM $\{E_1,\dots,E_{m+1}\}$ such that if outcome $E_i$ occurs for $1\le i\le m$ then Bob knows with certainty that he was give the state $\ket{\psi_i}$. (The POVM must be such that $\bra{\psi_i}E_i\ket{\psi_i}>0$ for each $i$.)
  \begin{proof}
    Let $E_i=\ket{\psi_i}\bra{\psi_i}$ for $1\le i\le m$ and $E_{m+1}=I-\sum E_i$. Then for $1\le i \le m$, we have
    \begin{eqnarray*}
      \bra{\psi_i}E_j\ket{\psi_i}&=&
      \bra{\psi_i}\ket{\psi_j}\bra{psi_j}\ket{\psi_i} \\
      &=&\delta_{i,j}\delta_{i,j}.
    \end{eqnarray*}
    Therefore we only get $E_i$ when we also have $\psi_i$. It's also easy to see that $E_{m+1}$ won't happen for $\psi_i$.
  \end{proof}
\end{exercise}

%2.65
\begin{exercise}
  Express the states $(\bra{0}+\bra{1})/\sqrt2$ and $(\bra{0}-\bra{1})/\sqrt2$ in a basis in which they are \textit{not} the same up to a relative phase shift.
  \begin{proof}
    These elements are the elements $\ket{+}$ and $\ket{-}$, so in that basis they are not the same up to a relative phase shift.
  \end{proof}
\end{exercise}

%2.66
\begin{exercise}
  Show that the average value of the observable $X_1Z_2$ for a two qubit system measured in the state $(\ket{00}+\ket{11})/\sqrt2$ is zero.
  \begin{proof}
    Let $\psi=(\ket{00}+\ket{11})/\sqrt2$. We have
    \begin{eqnarray*}
      \bra{\psi}X_1Z_2\ket{\psi}&=&
      \bra{\psi}X_1Z_2(\ket{00}+\ket{11})/\sqrt2 \\
      &=&\bra{\psi}X_1(\ket{00}-\ket{11})/\sqrt2 \\
      &=&\frac{1}{2}(\bra{00}+\bra{11})(\ket{10}-\ket{01}) \\
      &=&0
    \end{eqnarray*}
  \end{proof}
\end{exercise}

%2.67
\begin{exercise}
  Suppose $V$ is a Hilbert space with subspace $W$. Suppose $U:W\rightarrow U$ is a linear operator which preserves inner products, that is, for any $\ket{w_1}$ and $\ket{w_2}$ in $W$,
  \[\bra{w_1}U^\dagger U\ket{w_2}=\braket{w_1}{w_2}.\]
  Prove that there exists a unitary operator $U':V\rightarrow V$ which \textit{extends} $U$. That is, $U'\ket{w}=U\ket{w}$ for all $w\in W$, but $U'$ is defined on the entire space $V$. Usually we omit the prime symbol and just write $U$ to denote the extension.
  \begin{proof}
    Let the set $\{\ket{w_i}\}$ be an orthonormal basis for $W$. We extend this set with elements $\{\ket{v_j}\}$ such that $\{\ket{w_i}\}\cup \{\ket{v_j}\}$ forms an orthonormal basis of $V$.

    On elements $v_j$ we define $U'$ such that $U'\ket{v_j}=\ket{v_j}$. Then we can linearly extend it to finite linear combinations of elements of $\{\ket{w_i}\}\cup \{\ket{v_j}\}$. It is straight forward to see that we still have inner products preserved.
  \end{proof}
\end{exercise}

% 2.68
\begin{exercise}
  Define
  \[\ket\psi = \frac{\ket{00}+\ket{11}}{\sqrt2}.\]
  Prove that $\psi\ne\ket{a}\ket{b}$ for all single qubit states $\ket{a}$ and $\ket{b}$.
  \begin{proof}
    Define $\ket{a}=a_0\ket0+a_1\ket1$ and $\ket{b}=b_0\ket0+b_1\ket1$. Then we have
    \begin{eqnarray*}
      \ket{a}\ket{b}&=&(a_0\ket0+a_1\ket1)(b_0\ket0+b_1\ket1) \\
      &=&a_0b_0\ket{00}+a_0b_1\ket{01}+a_1b_0\ket{01}+a_1b_1\ket{11}.
    \end{eqnarray*}
    To have $\ket{\psi}=\ket{a}\ket{b}$ we need to have $a_0b_0=1$ and $a_1b_1=1$. This means that we need $a_0,a_1,b_0,b_1\ne0$. But we also have to have $a_0b_1=0$ and $a_1b_0=0$. This is impossible because none of the values can be $0$.
  \end{proof}
\end{exercise}

%2.69
\begin{exercise}
  Verify that the Bell basis forms an orthonormal basis for the two qubit state space.
  \begin{proof}
    This is straight forward as the only elements from the Bell states that have shared elements have a single element with an opposite sign.
  \end{proof}
\end{exercise}

% 2.70
\begin{exercise}
  Suppose that $E$ is any positive operator acting on Alice's qubit. Show that $\ket{\psi}E\otimes I\ket{\psi}$ takes the same value when $\ket{\psi}$ is any of the four Bell states. Suppose an malevolent third party, Eve, intercepts Alice's qubit on the way to Bob in the superdence coding protocol. Can Eve infer anything about which of the four possible bit strings $00$, $01$, $10$, $11$ Alice is trying to send? If so, how, or if not, why not?
  \begin{proof}

  \end{proof}
\end{exercise}

% 2.71
\begin{exercise}
  Let $\rho$ be a density operator. Show that $\textrm{tr}(\rho^2)\ge1$, with equality if and only if $\rho$ is a pure state.
  \begin{proof}
    Let $\rho=\sum p_i\ket{\psi_i}\bra{\psi_i}$ be a density operator. Then
    \begin{eqnarray*}
      \rho^2&=&(\sum_i p_i\ket{\psi_i}\bra{\psi_i})(\sum_j p_j\ket{\psi_j}\bra{\psi_j}) \\
      &=&\sum_i\sum_j p_i p_j \ket{\psi_i}\bra{\psi_i}\ket{\psi_j}\bra{\psi_j} \\
      &=&\sum_i\sum_j p_i p_j \ket{\psi_i}\delta_{i,j}\bra{\psi_j} \\
      &=&\sum_i p_i^2 \ket{\psi_i}\bra{\psi_i} \\
    \end{eqnarray*}
    Now since $p_i>0$ and $\sum p_i=1$ then $\sum p_i^2\le 1$. Now if any $p_i\ne1$ then $\sum p_i^2<1$. That is, that means that $\rho$ is not pure. On the other hand if $\rho$ is pure than $p_i=1$ for one $p_i$ and we have $\textrm{tr}(\rho^2)=1$
  \end{proof}
\end{exercise}

% 2.72
\begin{exercise}[Bloch sphere for mixed states]
  The Block sphere picture for states of a single qubit was introduced in section 1.2. This description has an important generalization to mixed states as follows.
  \begin{enumerate}
    \item Show that an arbitrary density matrix for a mized state qubit may be written as
    \[\rho = \frac{I + r\cdot v}{2},\]
    where $r$ is a real three-dimensional vector such that $||r||\le 1$. This vector is known as the \textit{Bloch vector} for the state $\rho$.
    \item What is the Bloch vector representaiton for the state $\rho=I/2$?
    \item Show that a state $\rho$ is pure if and only if $||r||=1$.
    \item Show that for pure states the description of the Bloch vector we have given coincises with that in Section 1.2.
  \end{enumerate}
\end{exercise}

% 2.73
\begin{exercise}
  Let $\rho$ be a density operator. A \textit{minimal ensemble} for $\rho$ is an ensemble $\{p_i,\ket{\psi_i}\}$ containing a number of elements equal to the rank of $\rho$. Let $\ket{\psi}$ be any state in the support of $\rho$. Show that there is a minimal ensemble for $\rho$ that contains $\ket\psi$, and moreover that in any such ensemble $\ket\psi$ must appear with probability
  \[p_i=\frac{1}{\bra{\psi_i}\rho^{-1}\ket{\psi_i}},\]
  where $\rho^{-1}$ is defined to be the inverse of $\rho$.
\end{exercise}
\end{document}
